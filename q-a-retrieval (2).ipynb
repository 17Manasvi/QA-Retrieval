{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentence-transformers groq","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:49:34.018632Z","iopub.execute_input":"2024-10-18T15:49:34.019263Z","iopub.status.idle":"2024-10-18T15:49:48.381419Z","shell.execute_reply.started":"2024-10-18T15:49:34.019221Z","shell.execute_reply":"2024-10-18T15:49:48.380455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install datasets\n!pip install transformers faiss-cpu torch datasets\n!pip install einops","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:49:48.383846Z","iopub.execute_input":"2024-10-18T15:49:48.384188Z","iopub.status.idle":"2024-10-18T15:50:24.548612Z","shell.execute_reply.started":"2024-10-18T15:49:48.384152Z","shell.execute_reply":"2024-10-18T15:50:24.547468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load the dataset- HotspotQA","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the HotpotQA dataset\ndataset = load_dataset(\"hotpot_qa\", \"fullwiki\")\n\n# Check out the dataset structure\nprint(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:50:24.550159Z","iopub.execute_input":"2024-10-18T15:50:24.550581Z","iopub.status.idle":"2024-10-18T15:55:04.877667Z","shell.execute_reply.started":"2024-10-18T15:50:24.550533Z","shell.execute_reply":"2024-10-18T15:55:04.876765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Taking only 100 data points due to computational constraints","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\ncontext = []\nfor i in tqdm(dataset['train']['context'][:100]):\n    for j in i['sentences']:\n        for sent in j:\n            context.append(sent)\ncontext = list(set(context))","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:55:04.880051Z","iopub.execute_input":"2024-10-18T15:55:04.880364Z","iopub.status.idle":"2024-10-18T15:55:17.750045Z","shell.execute_reply.started":"2024-10-18T15:55:04.880328Z","shell.execute_reply":"2024-10-18T15:55:17.748188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions = dataset['train']['question'][:100]\nanswer = dataset['train']['answer'][:100]","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:55:17.753035Z","iopub.execute_input":"2024-10-18T15:55:17.753718Z","iopub.status.idle":"2024-10-18T15:55:18.037728Z","shell.execute_reply.started":"2024-10-18T15:55:17.753671Z","shell.execute_reply":"2024-10-18T15:55:18.036480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:55:18.039462Z","iopub.execute_input":"2024-10-18T15:55:18.039941Z","iopub.status.idle":"2024-10-18T15:55:18.048457Z","shell.execute_reply.started":"2024-10-18T15:55:18.039897Z","shell.execute_reply":"2024-10-18T15:55:18.046909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"answer[0]","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:55:18.050328Z","iopub.execute_input":"2024-10-18T15:55:18.050946Z","iopub.status.idle":"2024-10-18T15:55:18.058646Z","shell.execute_reply.started":"2024-10-18T15:55:18.050903Z","shell.execute_reply":"2024-10-18T15:55:18.057804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(context)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:55:18.059867Z","iopub.execute_input":"2024-10-18T15:55:18.060225Z","iopub.status.idle":"2024-10-18T15:55:18.069772Z","shell.execute_reply.started":"2024-10-18T15:55:18.060185Z","shell.execute_reply":"2024-10-18T15:55:18.068784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Retrieval and Reranking","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nimport torch\nimport faiss","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:55:18.070773Z","iopub.execute_input":"2024-10-18T15:55:18.071152Z","iopub.status.idle":"2024-10-18T15:55:24.731521Z","shell.execute_reply.started":"2024-10-18T15:55:18.071120Z","shell.execute_reply":"2024-10-18T15:55:24.730539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HF_TOKEN = \"HUGGING_FACE_TOKEN\"","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:55:24.732801Z","iopub.execute_input":"2024-10-18T15:55:24.733380Z","iopub.status.idle":"2024-10-18T15:55:24.737571Z","shell.execute_reply.started":"2024-10-18T15:55:24.733343Z","shell.execute_reply":"2024-10-18T15:55:24.736632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\", use_auth_token = HF_TOKEN)\nmodel = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\", use_auth_token = HF_TOKEN)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:55:24.738895Z","iopub.execute_input":"2024-10-18T15:55:24.739196Z","iopub.status.idle":"2024-10-18T15:55:30.214467Z","shell.execute_reply.started":"2024-10-18T15:55:24.739164Z","shell.execute_reply":"2024-10-18T15:55:30.213425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Getting embeddings of corpus and questions","metadata":{}},{"cell_type":"code","source":"# creating embeddings\ndef get_embedding(text, tokenizer, model):\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n    with torch.no_grad():\n        outputs = model(**inputs)\n    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n\ncorpus_embeddings = [get_embedding(doc, tokenizer, model) for doc in tqdm(context)]\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:55:30.215781Z","iopub.execute_input":"2024-10-18T15:55:30.216256Z","iopub.status.idle":"2024-10-18T15:57:47.067302Z","shell.execute_reply.started":"2024-10-18T15:55:30.216220Z","shell.execute_reply":"2024-10-18T15:57:47.066320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_embedding = [get_embedding(ques, tokenizer, model) for ques in tqdm(questions)]","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:57:47.068597Z","iopub.execute_input":"2024-10-18T15:57:47.068910Z","iopub.status.idle":"2024-10-18T15:57:50.116134Z","shell.execute_reply.started":"2024-10-18T15:57:47.068875Z","shell.execute_reply":"2024-10-18T15:57:50.115208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Creating FAISS index and searching top 10 documents for 1st query (question[0])","metadata":{}},{"cell_type":"code","source":"import numpy as np\n# Initialize FAISS index\nembedding_dim = corpus_embeddings[0].shape[0]\nindex = faiss.IndexFlatL2(embedding_dim)\n\n# Add corpus embeddings to the index\ncorpus_embeddings_np = np.array(corpus_embeddings)\nindex.add(corpus_embeddings_np)\n\n# Search for top-k nearest documents\nk = 3\n_, top_k_indices = index.search(np.expand_dims(query_embedding[0], axis=0), k)\n\n# Retrieve top-k documents\ntop_k_documents = [context[idx] for idx in top_k_indices[0]]\nprint(\"Question:\", questions[0])\nprint(\"Top-k documents:\", top_k_documents)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:57:50.119774Z","iopub.execute_input":"2024-10-18T15:57:50.120095Z","iopub.status.idle":"2024-10-18T15:57:50.140227Z","shell.execute_reply.started":"2024-10-18T15:57:50.120054Z","shell.execute_reply":"2024-10-18T15:57:50.139156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reranking","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import CrossEncoder\n\ncross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:57:50.141727Z","iopub.execute_input":"2024-10-18T15:57:50.142313Z","iopub.status.idle":"2024-10-18T15:58:13.158228Z","shell.execute_reply.started":"2024-10-18T15:57:50.142263Z","shell.execute_reply":"2024-10-18T15:58:13.157451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sort_indices_descending(lst):\n    return sorted(range(len(lst)), key=lambda i: lst[i], reverse=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:58:13.159625Z","iopub.execute_input":"2024-10-18T15:58:13.160229Z","iopub.status.idle":"2024-10-18T15:58:13.164978Z","shell.execute_reply.started":"2024-10-18T15:58:13.160193Z","shell.execute_reply":"2024-10-18T15:58:13.164136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def retrieve_tok_k_items(query_idx, top_k=10):\n    query = [questions[query_idx]]\n    q_embed = query_embedding[query_idx]\n    D, I = index.search(np.expand_dims(q_embed, axis = 0), top_k)\n    \n    top_k_idx = I[0]\n    top_k_documents = [context[idx] for idx in I[0]]\n\n    return top_k_documents","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:58:13.166132Z","iopub.execute_input":"2024-10-18T15:58:13.166483Z","iopub.status.idle":"2024-10-18T15:58:13.176986Z","shell.execute_reply.started":"2024-10-18T15:58:13.166447Z","shell.execute_reply":"2024-10-18T15:58:13.176084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_context_docs(query_idx):\n    flat_list = [item for sublist in dataset['train']['context'][query_idx]['sentences'] for item in sublist]\n    return flat_list","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:58:13.178116Z","iopub.execute_input":"2024-10-18T15:58:13.178510Z","iopub.status.idle":"2024-10-18T15:58:13.186426Z","shell.execute_reply.started":"2024-10-18T15:58:13.178465Z","shell.execute_reply":"2024-10-18T15:58:13.185684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_reranked_docs(query_idx):\n    cross_input_list = []\n    top_k_documents = retrieve_tok_k_items(query_idx)\n    for item in top_k_documents:\n        new_list = [questions[query_idx], item]\n        cross_input_list.append(new_list)\n        \n    cross_scores = cross_encoder.predict(cross_input_list)\n    order_of_ranking = sort_indices_descending(cross_scores)\n    print(order_of_ranking)\n    ranked_docs = []\n    is_in_orig_context = []\n    flat_list = get_context_docs(query_idx)\n    for j in order_of_ranking:\n        ranked_docs.append(cross_input_list[j][1])\n        is_in_orig_context.append(cross_input_list[j][1] in flat_list)\n    \n    return ranked_docs, sorted(cross_scores, reverse=True), is_in_orig_context","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:58:13.187431Z","iopub.execute_input":"2024-10-18T15:58:13.187728Z","iopub.status.idle":"2024-10-18T15:58:13.198272Z","shell.execute_reply.started":"2024-10-18T15:58:13.187687Z","shell.execute_reply":"2024-10-18T15:58:13.197321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def assign_relevance_labels(reranking_scores):\n\n    # Step 1: Normalize the reranking scores to range [0, 1]\n    min_score = np.min(reranking_scores)\n    max_score = np.max(reranking_scores)\n    normalized_scores = (reranking_scores - min_score) / (max_score - min_score)\n\n    # Step 2: Define thresholds for relevance bins\n    n_docs = len(normalized_scores)\n    sorted_indices = np.argsort(-normalized_scores)  # Sort in descending order\n\n    top_20_percent = int(n_docs * 0.2)\n    next_30_percent = int(n_docs * 0.3)\n\n    # Step 3: Assign relevance labels based on thresholds\n    relevance_labels = np.zeros(n_docs)\n    relevance_labels[sorted_indices[:top_20_percent]] = 2  # Top 20% -> relevance 2\n    relevance_labels[sorted_indices[top_20_percent:top_20_percent + next_30_percent]] = 1  # Next 30% -> relevance 1\n    relevance_labels[sorted_indices[top_20_percent + next_30_percent:]] = 0  # Bottom 50% -> relevance 0\n\n    return relevance_labels\n\n\"\"\"\n\ndef assign_relevance_labels(reranking_scores):\n    relevance_labels = []\n    for r in reranking_scores:\n        if(r>0):\n            relevance_labels.append(1)\n        else:\n            relevance_labels.append(0)\n    return relevance_labels\n    \n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:58:13.199475Z","iopub.execute_input":"2024-10-18T15:58:13.199839Z","iopub.status.idle":"2024-10-18T15:58:13.212051Z","shell.execute_reply.started":"2024-10-18T15:58:13.199798Z","shell.execute_reply":"2024-10-18T15:58:13.211215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from groq import Groq\n\nclient = Groq(api_key = \"GROQ_API_KEY\")","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:58:13.213020Z","iopub.execute_input":"2024-10-18T15:58:13.213296Z","iopub.status.idle":"2024-10-18T15:58:14.101709Z","shell.execute_reply.started":"2024-10-18T15:58:13.213266Z","shell.execute_reply":"2024-10-18T15:58:14.100748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def assign_actual_relevance_scores(df):\n    df['relevance_scores_actual'] = np.nan\n    for i in range(len(df)):\n        completion = client.chat.completions.create(\n        model=\"llama3-70b-8192\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": \"Given a context and a question, provide relevance rating to the context based on how relevant the context is in answering the question. The relevance ratings can only be one of 0 (completely irrelevant), 1(somewhat relevant), 2(completely relevant).\\n\\noutput only the relevance rating\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"Context: {df['ranked_retrieved_docs'].iloc[i]}\\n\\nQuestion: {df['query'].iloc[i]}\"\n            }\n        ],\n            temperature=1,\n            max_tokens=1024,\n            top_p=1,\n            stream=False,\n            stop=None,\n        )\n    \n        df['relevance_scores_actual'].iloc[i] = completion.choices[0].message.content\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:58:14.103001Z","iopub.execute_input":"2024-10-18T15:58:14.103384Z","iopub.status.idle":"2024-10-18T15:58:14.110934Z","shell.execute_reply.started":"2024-10-18T15:58:14.103340Z","shell.execute_reply":"2024-10-18T15:58:14.109783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nranked_docs, cross_scores, is_in_orig_context = get_reranked_docs(8)\ndf = pd.DataFrame(ranked_docs, columns = ['ranked_retrieved_docs'])\ndf['ranked_retrieved_docs_score'] = cross_scores\ndf['is_in_orig_context'] = is_in_orig_context\ndf['query'] = questions[8]\nrelevance_labels = assign_relevance_labels(df['ranked_retrieved_docs_score'].values)\nprint(relevance_labels)\ndf['relevance_labels_reranked'] = relevance_labels\ndf = assign_actual_relevance_scores(df)\ndf","metadata":{"execution":{"iopub.status.busy":"2024-10-18T17:39:32.270015Z","iopub.execute_input":"2024-10-18T17:39:32.270639Z","iopub.status.idle":"2024-10-18T17:39:48.102292Z","shell.execute_reply.started":"2024-10-18T17:39:32.270596Z","shell.execute_reply":"2024-10-18T17:39:48.101446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n\ndf_sorted = df.sort_values(by='relevance_labels_reranked', ascending=False)\n\n# Calculate DCG\ndef dcg_at_k(relevance_scores, k):\n    relevance_scores = np.asfarray(relevance_scores)[:k]\n    if relevance_scores.size:\n        return np.sum((2 ** relevance_scores - 1) / np.log2(np.arange(1, relevance_scores.size + 1) + 1))\n    return 0.0\n\n# Calculate IDCG (Ideal DCG) - ideal relevance is sorted in descending order\ndef idcg_at_k(relevance_scores, k):\n    ideal_relevance = sorted(relevance_scores, reverse=True)\n    return dcg_at_k(ideal_relevance, k)\n\n# Calculate nDCG\ndef ndcg_at_k(actual_relevance_scores, predicted_relevance_scores, k):\n    # Calculate DCG using actual relevance scores in the order of predicted relevance\n    dcg = dcg_at_k(actual_relevance_scores, k)\n    \n    # Calculate IDCG using the actual relevance scores sorted ideally\n    idcg = idcg_at_k(actual_relevance_scores, k)\n    \n    return dcg / idcg if idcg > 0 else 0.0\n\n# Get the actual relevance scores after sorting by the predicted relevance\nactual_relevance_scores = np.float64(df_sorted['relevance_scores_actual'])\npredicted_relevance_scores = df_sorted['relevance_labels_reranked']\n\n# Set k (you can choose a specific value or use the full list)\nk = len(actual_relevance_scores)  # Or choose any k value\n\n# Calculate nDCG\nndcg_value = ndcg_at_k(actual_relevance_scores, predicted_relevance_scores, k)\nprint(f\"nDCG at {k}: {ndcg_value}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T17:39:53.489723Z","iopub.execute_input":"2024-10-18T17:39:53.490088Z","iopub.status.idle":"2024-10-18T17:39:53.501567Z","shell.execute_reply.started":"2024-10-18T17:39:53.490053Z","shell.execute_reply":"2024-10-18T17:39:53.500661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_ndcg_at_10 = 0\nfor q in tqdm(range(len(questions))):\n    ranked_docs, cross_scores, is_in_orig_context = get_reranked_docs(q)\n    df = pd.DataFrame(ranked_docs, columns = ['ranked_retrieved_docs'])\n    df['ranked_retrieved_docs_score'] = cross_scores\n    df['is_in_orig_context'] = is_in_orig_context\n    df['query'] = questions[q]\n    relevance_labels = assign_relevance_labels(df['ranked_retrieved_docs_score'].values)\n    df['relevance_labels_reranked'] = relevance_labels\n    df = assign_actual_relevance_scores(df)\n    k = 10\n    df_sorted = df.sort_values(by='relevance_labels_reranked', ascending=False)\n    actual_relevance_scores = df_sorted['relevance_scores_actual']\n    predicted_relevance_scores = df_sorted['relevance_labels_reranked']\n    ndcg_score = ndcg_at_k(actual_relevance_scores, predicted_relevance_scores, k)\n    print(f\"NDCG Score for Query {q} is {ndcg_score}\")\n    total_ndcg_at_10+=ndcg_score\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T15:58:30.596714Z","iopub.execute_input":"2024-10-18T15:58:30.597063Z","iopub.status.idle":"2024-10-18T16:37:30.829976Z","shell.execute_reply.started":"2024-10-18T15:58:30.597022Z","shell.execute_reply":"2024-10-18T16:37:30.829075Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Average NDCG Score on {len(questions)} queries is: {total_ndcg_at_10/len(questions)}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-18T16:58:37.310567Z","iopub.execute_input":"2024-10-18T16:58:37.311497Z","iopub.status.idle":"2024-10-18T16:58:37.316278Z","shell.execute_reply.started":"2024-10-18T16:58:37.311438Z","shell.execute_reply":"2024-10-18T16:58:37.315384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_prec = 0\ntotal_recall = 0\nfor q in tqdm(range(len(questions))):\n    ranked_docs, cross_scores, is_in_orig_context = get_reranked_docs(q)\n    df = pd.DataFrame(ranked_docs, columns = ['ranked_retrieved_docs'])\n    df['ranked_retrieved_docs_score'] = cross_scores\n    df['is_in_orig_context'] = is_in_orig_context\n    df['query'] = questions[q]\n    relevance_labels = assign_relevance_labels(df['ranked_retrieved_docs_score'].values)\n    df['relevance_labels_reranked'] = relevance_labels\n    df = assign_actual_relevance_scores(df)\n    k = 10\n    #df_sorted = df.sort_values(by='relevance_labels_reranked', ascending=False)\n    relevant_docs = 0\n    actual_relevant_docs = 0\n    df['relevance_scores_actual'] = np.float64(df['relevance_scores_actual'].values)\n    for i in range(k):\n        if(df['relevance_labels_reranked'].iloc[i]>0 and df['relevance_scores_actual'].iloc[i]>0):\n            relevant_docs+=1\n        if(df['relevance_scores_actual'].iloc[i]>0):\n            actual_relevant_docs+=1\n    precision_at_k = relevant_docs/k\n    recall_at_k = 0\n    if actual_relevant_docs!=0 : \n        recall_at_k = relevant_docs/actual_relevant_docs\n    \n    print(f\"Precision Score for Query {q} is {precision_at_k}\")\n    print(f\"Recall Score for Query {q} is {recall_at_k}\")\n    total_prec+=precision_at_k\n    total_recall+=recall_at_k\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T17:41:21.117079Z","iopub.execute_input":"2024-10-18T17:41:21.117495Z","iopub.status.idle":"2024-10-18T18:20:21.202663Z","shell.execute_reply.started":"2024-10-18T17:41:21.117454Z","shell.execute_reply":"2024-10-18T18:20:21.201605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Average Precision Score on {len(questions)} queries is: {total_prec/len(questions)}\")\nprint(f\"Average Recall Score on {len(questions)} queries is: {total_recall/len(questions)}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-18T18:20:21.204611Z","iopub.execute_input":"2024-10-18T18:20:21.205273Z","iopub.status.idle":"2024-10-18T18:20:21.210689Z","shell.execute_reply.started":"2024-10-18T18:20:21.205225Z","shell.execute_reply":"2024-10-18T18:20:21.209875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}